{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "NERTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NrzMCAdjZMS"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/token-classification/run_ner.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/token-classification/utils_ner.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/token-classification/tasks.py\n",
        "\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyP1hpw3jZMX"
      },
      "source": [
        "!mkdir data\n",
        "# aynı dizinde data klasöründe train,test,dev tsv dosyaları yükleniyor.\n",
        "# eğer text dosyaları varsa hazır, direk run_ner.py çalıştırılabilir.\n",
        "\n",
        "blankLineIndicator = \"BlankLineIndicator\"\n",
        "blank = \"\"\n",
        "firstColumnIndex = 0\n",
        "secondColumnIndex = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32D2nCI8jZMa"
      },
      "source": [
        "import pandas as pd\n",
        "train_pd = pd.read_csv(\"./data/train.tsv\",sep='\\t',skip_blank_lines=False)\n",
        "test_pd = pd.read_csv(\"./data/test.tsv\",sep='\\t',skip_blank_lines=False)\n",
        "dev_pd = pd.read_csv(\"./data/dev.tsv\",sep='\\t',skip_blank_lines=False)\n",
        "\n",
        "# boş satıları -X1 ile dolduruyoruz ki cümlenin ne zaman bittiğini görebilelim\n",
        "train_pd.fillna(blankLineIndicator,inplace=True)\n",
        "test_pd.fillna(blankLineIndicator,inplace=True)\n",
        "dev_pd.fillna(blankLineIndicator,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pe-8PBpkRLp"
      },
      "source": [
        "print(train_pd.columns)\n",
        "print(test_pd.columns)\n",
        "print(dev_pd.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-0xfwPrjZMd"
      },
      "source": [
        "train_tsv = []\n",
        "for index, row in train_pd.iterrows():\n",
        "            #Token Sütun İsmi\n",
        "    if row[firstColumnIndex] == blankLineIndicator:\n",
        "        train_tsv.append(blank)\n",
        "    else:               #Token Sütun İsmi\n",
        "        train_tsv.append(str(row[firstColumnIndex]) +  \" \" + row[secondColumnIndex])\n",
        "\n",
        "test_tsv = []\n",
        "for index, row in test_pd.iterrows():\n",
        "    #Token Sütun İsmi\n",
        "    if row[firstColumnIndex] == blankLineIndicator:\n",
        "        test_tsv.append(blank)\n",
        "    else:              #Token Sütun İsmi\n",
        "        test_tsv.append(str(row[firstColumnIndex]) +  \" \" + row[secondColumnIndex])\n",
        "\n",
        "dev_tsv = []\n",
        "for index, row in dev_pd.iterrows():\n",
        "    #Token Sütun İsmi\n",
        "    if row[firstColumnIndex] == blankLineIndicator:\n",
        "        dev_tsv.append(blank)\n",
        "    else:           #Token Sütun İsmi\n",
        "        dev_tsv.append(str(row[firstColumnIndex]) +  \" \" + row[secondColumnIndex])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrM38jYjZMg"
      },
      "source": [
        "def create_txt(file_name,lines):\n",
        "    file = open(file_name, 'w') \n",
        "    for line in lines:\n",
        "        file.write(line + \"\\n\") \n",
        "    file.close()\n",
        "\n",
        "create_txt(\"./data/train.txt\",train_tsv)\n",
        "create_txt(\"./data/test.txt\",test_tsv)\n",
        "create_txt(\"./data/dev.txt\",dev_tsv)\n",
        "# txt file'a çeviriyoruz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP4TrR-4jZMj"
      },
      "source": [
        "#labels.txt -> unique varlık ismi sınıflarının olduğu text dosyası"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu4lDmq5kr5z"
      },
      "source": [
        "import numpy as np\n",
        "column_values = train_pd[[\"O\"]].values\n",
        "unique_values =  np.unique(column_values)\n",
        "print(unique_values)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mGNFcBFjZMl"
      },
      "source": [
        "OUTPUT_DIR = \"electra-ner\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wgmcr74jZMo"
      },
      "source": [
        "!pip install pyarrow --upgrade\n",
        "\n",
        "!python3 run_ner.py --data_dir ./data \\\n",
        "--labels ./labels.txt \\\n",
        "--model_name_or_path fspanda/electra-medical-small-generator \\\n",
        "--output_dir $OUTPUT_DIR \\\n",
        "--max_seq_length 192 \\\n",
        "--num_train_epochs 3 \\\n",
        "--per_device_train_batch_size 16 \\\n",
        "--overwrite_output_dir \\\n",
        "--save_steps 10000 \\\n",
        "--seed 41 \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--do_predict"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}